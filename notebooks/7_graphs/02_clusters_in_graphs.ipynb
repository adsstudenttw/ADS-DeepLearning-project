{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using eigenvectors to find clusters in Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZACHARY KARATE CLUB\n",
    "\n",
    "dataset [zachary](http://vlado.fmf.uni-lj.si/pub/networks/data/Ucinet/UciData.htm#zachary)\n",
    "\n",
    "The graph is based on a real-life social experiment at a university karate club. Zachary[1] observed the interactions outside of the dojo between 34 members of the club over a period of three years. During his study, a conflict arose between the administrator of the club, referred to as \"Mr. Hi\", and the club's instructor, often labeled as \"John A\", which eventually led to the club splitting into two different clubs, each led by one of these two individuals.\n",
    "\n",
    "When you run community detection algorithms, such as spectral clustering, on this graph, they should ideally detect the two communities corresponding to the split in the karate club.\n",
    "\n",
    "1: Zachary W. (1977). An information flow model for conflict and fission in small groups. Journal of Anthropological Research, 33, 452-473."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "pos = nx.spring_layout(G, seed=46)\n",
    "nx.draw(G, with_labels=True, pos=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map the labels to numbers for coloring\n",
    "label_map = {'Mr. Hi': 0, 'Officer': 1}\n",
    "\n",
    "# Extract the labels and convert them to numbers\n",
    "node_colors = [label_map[G.nodes[node]['club']] for node in G.nodes()]\n",
    "nx.draw(G, node_color=node_colors, with_labels=True, pos=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you have a network of friends where the nodes are you and your friends, and the lines (edges) between the nodes are the friendships. The Laplacian matrix is like a ledger that helps keep track of the friendships in a very particular way.\n",
    "\n",
    "Here's how you make this ledger:\n",
    "\n",
    "- Who has how many friends (number of edges from every node): First, you write down a list of how many friends each person has. This is like a tally for each person.\n",
    "- Who is friends with whom (edges between nodes): Next, you make a grid where you mark who is directly friends with whom.\n",
    "\n",
    "More technically, this is defined like this:\n",
    "- Degree Matrix (D): This is a diagonal matrix where each diagonal element D[i][i] equals the sum of the weights of the edges connected to node i. For an unweighted graph, it's just the number of edges connected to node i.\n",
    "- Adjacency Matrix (A): This is a square matrix that represents the graph. If there is an edge between nodes i and j, then A[i][j] is positive (often 1 for unweighted graphs, or a weight for weighted graphs). If there is no edge, A[i][j] is zero.\n",
    "\n",
    "Now, the Laplacian matrix (L) combines this information by doing a simple calculation: for each person, subtract the number of direct friends they have from the number of total friends.\n",
    "\n",
    " $$L = D - A$$\n",
    "\n",
    "This matrix has some neat properties:\n",
    "\n",
    "If you add up all the numbers in any row or column, the sum is zero. It's like saying, \"This person has as many friends as they have friends.\"\n",
    "\n",
    "The way the numbers are arranged and the values they have can tell you if there are groups of friends who are all connected to each other but not much to others in the network. It's like spotting cliques in your group.\n",
    "\n",
    "The way the numbers in the Laplacian matrix are laid out can reveal hidden structures in the network, such as which groups of friends might form a club together or how you could split the group into two or more separate parties. It's a mathematical way to explore the social circles within the network.\n",
    "\n",
    "When we cluster a network, we can use eigenvectors to help us see the shape of the network and the underlying structure. The eigenvectors reveal the most important connections and ignore the less important ones. \n",
    "They reveal clusters within the graph, as nodes within the same cluster tend to be represented close to each other in the low-dimensional space created by a subset of the eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Adjacency Matrix\n",
    "A = nx.adjacency_matrix(G).todense()\n",
    "\n",
    "# Create the Degree Matrix\n",
    "D = np.diag(A.sum(axis=1).flatten())\n",
    "\n",
    "# Compute the Laplacian Matrix\n",
    "L = D - A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of Principal Component Analysis (PCA) and other variance-based methods, larger eigenvalues indeed correspond to greater variance in the data, and thus the eigenvectors associated with the largest eigenvalues are typically the most significant. However, when it comes to the Laplacian matrix of a graph and spectral clustering, the smallest non-zero eigenvalues have a different and special role.\n",
    "\n",
    "The reason we look at the smallest non-zero eigenvalues (also known as the Fiedler value in the case of the second-smallest eigenvalue) when using the Laplacian matrix for clustering is due to the properties of the Laplacian and what these eigenvalues represent in the context of graph connectivity:\n",
    "\n",
    "\n",
    "- The smallest eigenvalue is always zero, and there is always at least one eigenvector associated with this zero eigenvalue. If there is exactly one eigenvalue that is zero (with its corresponding eigenvector), it indicates that the graph is connected; there is a path between every pair of nodes. If there are multiple eigenvalues that are zero (each with its corresponding eigenvector), the number of such zero eigenvalues indicates the number of disconnected components in the graph. Each of these eigenvectors will be constant within its component and zero elsewhere.\n",
    "\n",
    "- The second-smallest eigenvalue, or the first non-zero eigenvalue, provides insight into how the graph is connected. It helps to identify a cut that can partition the graph into two sparsely connected subgraphs. In a way, this value measures how easy it is to \"cut\" the graph into separate pieces.\n",
    "\n",
    "It can make sense to use more than the first two eigenvectors for clustering larger graphs, especially when the structure of the graph is complex and there are multiple clusters to identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the eigenvalues and eigenvectors\n",
    "vals, vecs = np.linalg.eigh(L)\n",
    "\n",
    "# Sort these based on the eigenvalues from smallest to largest\n",
    "vecs = vecs[:,np.argsort(vals)]\n",
    "vals = vals[np.argsort(vals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 34 eigenvectors\n",
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and 34 eigenvalues\n",
    "plt.scatter(np.arange(len(vals)), vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets visualize the eigenvectors. We will create two types of visualisation: \n",
    "One where the nodes are ordered on the x-axis based on there node-number (note that this will create some structure, which might be misleading) and on the y-axis the values of the eigenvectors are plotted.\n",
    "\n",
    "For the second eigenvector you can see that splitting the data around 0.0 will nicely split the data into two clusters that corresponds with the original labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "fig, ax = plt.subplots(2, n, figsize=(12, 8))\n",
    "\n",
    "for i in range(n):\n",
    "    v = vecs[:,i]\n",
    "    sns.scatterplot(x=range(len(v)), y=v, hue=node_colors, ax=ax[0, i], legend=False)\n",
    "    sns.histplot(x=v, ax=ax[1, i], bins=10, hue=node_colors, legend=False, kde=True)\n",
    "    ax[0, i].set_title(f'Eigenvector {i+1}')\n",
    "    ax[0, i].set_xlabel('Node number')\n",
    "    ax[1, i].set_xlabel('Bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you do this if it is more complex? You can run a sklearn clustering algorithm like KMeans (we will explore clustering models later on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = vecs[:, 1].reshape(-1, 1)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "clusters = kmeans.fit_predict(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the clusters in the eigenvector to color the nodes and lets see how well we did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# Use a color map\n",
    "color_map = plt.cm.get_cmap('viridis', 2)\n",
    "\n",
    "# Draw the nodes - the node color varies with the cluster\n",
    "nx.draw(G, pos, node_color=[color_map.colors[i] for i in clusters], with_labels=True, node_size=300, edge_color='gray', ax=ax[0])\n",
    "nx.draw(G, node_color=node_colors, with_labels=True, pos=pos, ax=ax[1])\n",
    "\n",
    "ax[0].set_title('Clusters from Eigenvectors')\n",
    "ax[1].set_title('True Club Membership')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
